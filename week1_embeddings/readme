Great resource by Lena Voita (direct link to Word Embeddings explanation): https://lena-voita.github.io/nlp_course/word_embeddings.html
Word2vec tutorial: http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/
Beautiful post by Jay Alammar: http://jalammar.github.io/illustrated-word2vec/
UMAP: https://habr.com/ru/company/newprolab/blog/350584/ 
t_SNE: https://habr.com/ru/company/newprolab/blog/350584/
stanford lectures (1-2) https://youtu.be/kEMJRjEdNzM


Unsupervised machine translation:
Exploiting Similarities among Languages for Machine Translation https://arxiv.org/pdf/1309.4168.pdf
WORD TRANSLATION WITHOUT PARALLEL DATA https://arxiv.org/pdf/1710.04087.pdf
Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation https://aclanthology.org/N15-1104.pdf 
